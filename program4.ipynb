{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2qUfsRnmApn",
        "outputId": "ed44621e-245b-45ed-847c-2b544d2c1d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Frequency:\n",
            "('language', 'modeling') : 1\n",
            "('modeling', 'is') : 1\n",
            "('is', 'an') : 1\n",
            "('an', 'important') : 1\n",
            "('important', 'part') : 1\n",
            "('part', 'of') : 1\n",
            "('of', 'natural') : 1\n",
            "('natural', 'language') : 1\n",
            "('language', 'processing') : 1\n",
            "('processing', '.') : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Input text\n",
        "text = \"Language modeling is an important part of Natural Language Processing.\"\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Generate bigrams (N = 2)\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "\n",
        "# Frequency distribution\n",
        "freq = FreqDist(bigrams)\n",
        "\n",
        "# Display result\n",
        "print(\"Bigram Frequency:\")\n",
        "for k, v in freq.items():\n",
        "    print(k, \":\", v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Input text\n",
        "text = \"Natural language processing enables machines to understand human language.\"\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Generate N-grams\n",
        "unigrams = tokens\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "\n",
        "# Print N-grams\n",
        "print(\"Unigrams:\", unigrams)\n",
        "print(\"Bigrams:\", bigrams)\n",
        "print(\"Trigrams:\", trigrams)\n",
        "\n",
        "# Frequency Distribution\n",
        "print(\"\\nMost Common Unigrams:\")\n",
        "print(FreqDist(unigrams).most_common(5))\n",
        "\n",
        "print(\"\\nMost Common Bigrams:\")\n",
        "print(FreqDist(bigrams).most_common(5))\n",
        "\n",
        "print(\"\\nMost Common Trigrams:\")\n",
        "print(FreqDist(trigrams).most_common(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5y3kavKtLeB",
        "outputId": "4495e63f-ebc0-4943-eac3-de622f890e73"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: ['natural', 'language', 'processing', 'enables', 'machines', 'to', 'understand', 'human', 'language', '.']\n",
            "Bigrams: [('natural', 'language'), ('language', 'processing'), ('processing', 'enables'), ('enables', 'machines'), ('machines', 'to'), ('to', 'understand'), ('understand', 'human'), ('human', 'language'), ('language', '.')]\n",
            "Trigrams: [('natural', 'language', 'processing'), ('language', 'processing', 'enables'), ('processing', 'enables', 'machines'), ('enables', 'machines', 'to'), ('machines', 'to', 'understand'), ('to', 'understand', 'human'), ('understand', 'human', 'language'), ('human', 'language', '.')]\n",
            "\n",
            "Most Common Unigrams:\n",
            "[('language', 2), ('natural', 1), ('processing', 1), ('enables', 1), ('machines', 1)]\n",
            "\n",
            "Most Common Bigrams:\n",
            "[(('natural', 'language'), 1), (('language', 'processing'), 1), (('processing', 'enables'), 1), (('enables', 'machines'), 1), (('machines', 'to'), 1)]\n",
            "\n",
            "Most Common Trigrams:\n",
            "[(('natural', 'language', 'processing'), 1), (('language', 'processing', 'enables'), 1), (('processing', 'enables', 'machines'), 1), (('enables', 'machines', 'to'), 1), (('machines', 'to', 'understand'), 1)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}